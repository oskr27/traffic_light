{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Dataset Constructor\n",
    "This notebook will apply the rules established during the image analysis, and create the training dataset for the CNN. The classes to be used are\n",
    "1. Stop\n",
    "2. Go\n",
    "3. Stop Left\n",
    "4. Go Left\n",
    "\n",
    "When warning, these images will be part of the stop batch, as well as warning left will be inserted on the Stop Left label. It is also important that the images will be subject to a normalization process so that all of them are 224-pixel-squared shape i.e. 224x224 pixels. During the process, we will pick random images to be part of the validation and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter related code\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported libraries\n",
    "from fastai.vision import *\n",
    "from PIL import Image\n",
    "from random import choices\n",
    "\n",
    "import random\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_width = 40\n",
    "min_height = 50\n",
    "\n",
    "def valid_sample(area):\n",
    "    width = area[2] - area[0]\n",
    "    height = area[3] - area[1]\n",
    "    \n",
    "    if width < min_width and height < min_height:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of area normalization function\n",
    "# The box is a tuple of four integers, x1, y1, x2, and y2\n",
    "# To obtain a normal area for this box, it is necessary to get the\n",
    "# center of the area, and expand the area to a 224x224 square shape\n",
    "def get_normal_area(box):\n",
    "    # Getting center of image\n",
    "    x_center = (box[0] + box[2]) // 2\n",
    "    y_center = (box[1] + box[3]) // 2\n",
    "\n",
    "    #Creating new tuple with expanded area\n",
    "    x_1 = x_center - 111;\n",
    "    y_1 = y_center - 111;\n",
    "    \n",
    "    x_2 = x_center + 112 if x_1 >= 0 else x_center + 112 - x_1\n",
    "    y_2 = y_center + 112 if y_1 >= 0 else y_center + 112 - y_1\n",
    "    \n",
    "    x_1 = x_1 if x_1 >= 0 else 0\n",
    "    y_1 = y_1 if y_1 >= 0 else 0\n",
    "    \n",
    "    return (x_1, y_1, x_2, y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of random path generator. This will return the output\n",
    "# file path (train or valid). The input parameters will\n",
    "# keep track of the distribution of these.\n",
    "def get_random_path(train_count, valid_count):\n",
    "    opts = ['train', 'valid']\n",
    "    prob = [0.7, 0.3]\n",
    "    \n",
    "    return choices(opts, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the image class depending on the input\n",
    "# The \"flag\" parameter is to condense the warning signal with stop\n",
    "def get_image_class(image_class, flag):\n",
    "    if flag:\n",
    "        if image_class == 'warning':\n",
    "            return 'stop'\n",
    "        elif image_class == 'warningLeft':\n",
    "            return 'stopLeft'\n",
    "        else:\n",
    "            return image_class\n",
    "    else:\n",
    "        return image_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths from where the original images can be obtained\n",
    "master_path = Path('../data/lisa-traffic-light-dataset')\n",
    "path_anno = master_path/'annotations'\n",
    "path_img = master_path/'images'\n",
    "\n",
    "# Adjust this variable to crop images from certain dayClip\n",
    "day_clip = ['dayClip1'\n",
    "            , 'dayClip2'\n",
    "            , 'dayClip3'\n",
    "            , 'dayClip4'\n",
    "            , 'dayClip5'\n",
    "            , 'dayClip6'\n",
    "            , 'dayClip7'\n",
    "            , 'dayClip8'\n",
    "            , 'dayClip9'\n",
    "            , 'dayClip10'\n",
    "            , 'dayClip11'\n",
    "            , 'dayClip12'\n",
    "            , 'dayClip13'\n",
    "           ]\n",
    "\n",
    "# Output paths for files\n",
    "path_master_output = Path('../data/training-dataset')\n",
    "\n",
    "# Modify this variable whenever you want to use a different input\n",
    "# CSV file\n",
    "annotations_file = 'frameAnnotationsBOX.csv'\n",
    "    \n",
    "for dayClip in day_clip:\n",
    "    # Input files\n",
    "    path_csv_train = path_anno/'dayTrain'/dayClip/annotations_file\n",
    "    path_image_input = path_img/'dayTrain'/dayClip/'frames'\n",
    "\n",
    "    # CSV Reader from annotations path\n",
    "    with open(path_csv_train) as csv_file:\n",
    "        reader = csv.reader(csv_file, delimiter = ';')\n",
    "\n",
    "        imageNumber = []\n",
    "        fileName = []\n",
    "        tag = []\n",
    "        box = []\n",
    "\n",
    "        i = -1\n",
    "        for row in reader:\n",
    "            imageNumber.append(i)\n",
    "            fileName.append(row[0].replace('dayTraining/', ''))\n",
    "            tag.append(row[1])\n",
    "            box.append((row[2], row[3], row[4], row[5]))\n",
    "            i = i + 1\n",
    "\n",
    "        # Removing headers\n",
    "        imageNumber.pop(0)\n",
    "        fileName.pop(0)\n",
    "        tag.pop(0)\n",
    "        box.pop(0)\n",
    "    \n",
    "    # The following code runs through all the dataset in \n",
    "    # path_image_input\n",
    "    i = 0    \n",
    "    while i < len(imageNumber):\n",
    "        im = Image.open(path_image_input/fileName[i])\n",
    "        \n",
    "        if valid_sample(tuple(map(int, box[i]))):\n",
    "            # Cropping the image\n",
    "            area = get_normal_area(tuple(map(int, box[i])))\n",
    "            cropped_im = im.crop(area)\n",
    "\n",
    "            # Checks if folder exists taking into account the amount of\n",
    "            # images in the training, testing, and validation folder\n",
    "            random_path = Path(get_random_path(train_count, valid_count)[0])\n",
    "            directory = path_master_output/random_path/get_image_class(tag[i], True)\n",
    "            # directory = directory/get_image_class(tag[i])\n",
    "\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "\n",
    "            # Crops the image and saves it under the listed directory\n",
    "            cropped_im.save(directory/Path(dayClip + '_' + str(imageNumber[i]) + '.jpg'))\n",
    "            \n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
